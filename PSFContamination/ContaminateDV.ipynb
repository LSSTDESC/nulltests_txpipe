{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9208e67e-b5d7-4e18-bff8-a2752687bd8a",
   "metadata": {},
   "source": [
    "making psf bias DV and contaminate simulated theory datavector <br>\n",
    "based on code from here:  https://github.com/des-science/Y3_shearcat_tests/blob/212c03bfc239c9cff5419efbe70bdfdba28639ec/alpha-beta-eta-test/code/produce_2pcfpsfbias.py\n",
    " <br> and here: https://github.com/des-science/Y3_shearcat_tests/blob/master/alpha-beta-eta-test/forecast/contaminate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0907aae-bd26-4bab-9c0a-f3693b7c9a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "from astropy.io import fits\n",
    "import itertools\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1195c7f-478c-40b9-8bbe-28b42bde41dd",
   "metadata": {},
   "source": [
    "# Make Contaminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d4c93-5306-4d3d-a8bd-a88607240ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the relevant files will all be in the TXdata folders:\n",
    "# des: '../desy3/TXdata/'\n",
    "# hsc: '../hscy3/TXdata/'\n",
    "# kids: '../KiDS/TXdata/'\n",
    "\n",
    "#copy and paste the path you want here:\n",
    "path= '../desy3/TXdata/'\n",
    "\n",
    "#DES and HSC have 4 bins, KiDS has 5.\n",
    "nbins=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646077a9-9927-4ac9-bee6-a8ea04289ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load rowes\n",
    "with h5py.File(path+'rowe_stats.hdf5') as f:\n",
    "    meanr = f['rowe_statistics/rowe_0_PSF-reserved/theta'][:]\n",
    "    rho0p = f['rowe_statistics/rowe_0_PSF-reserved/xi_plus'][:]\n",
    "    rho0m = f['rowe_statistics/rowe_0_PSF-reserved/xi_minus'][:]\n",
    "    rho1p = f['rowe_statistics/rowe_1_PSF-reserved/xi_plus'][:]\n",
    "    rho1m = f['rowe_statistics/rowe_1_PSF-reserved/xi_minus'][:]\n",
    "    rho2p = f['rowe_statistics/rowe_2_PSF-reserved/xi_plus'][:]\n",
    "    rho2m = f['rowe_statistics/rowe_2_PSF-reserved/xi_minus'][:]\n",
    "    rho3p = f['rowe_statistics/rowe_3_PSF-reserved/xi_plus'][:]\n",
    "    rho3m = f['rowe_statistics/rowe_3_PSF-reserved/xi_minus'][:]\n",
    "    rho4p = f['rowe_statistics/rowe_4_PSF-reserved/xi_plus'][:]\n",
    "    rho4m = f['rowe_statistics/rowe_4_PSF-reserved/xi_minus'][:]\n",
    "    rho5p = f['rowe_statistics/rowe_5_PSF-reserved/xi_plus'][:]\n",
    "    rho5m = f['rowe_statistics/rowe_5_PSF-reserved/xi_minus'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8358394-200a-4ce0-a804-1dc2d733d8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load tau fitting chains\n",
    "alist = []\n",
    "blist = []\n",
    "elist = []\n",
    "with h5py.File(path+'tau_chain.hdf5') as f:\n",
    "    for n in range(nbins):\n",
    "        alist.append(f[f'chain/bin_{n}/alpha'][:])\n",
    "        blist.append(f[f'chain/bin_{n}/beta'][:])\n",
    "        elist.append(f[f'chain/bin_{n}/eta'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bde8a7-f4f6-4833-88bf-77e483991cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.shape(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff20041-9b64-4d9f-963d-43c2d996c554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(alist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12af61-57f8-4283-ae3c-574ab1118f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=[i for i in range(nbins)]\n",
    "bin_pairs=[]\n",
    "for p in itertools.combinations_with_replacement(a, 2): bin_pairs.append(p)\n",
    "veclist = []\n",
    "for i,j in bin_pairs:\n",
    "    for z in range(len(alist[0])):\n",
    "        dxip = [alist[i][z]*alist[i][z]*rho0p + blist[i][z]*blist[j][z]*rho1p + elist[i][z]*elist[j][z]*rho3p + (blist[i][z]*alist[j][z] + blist[j][z]*alist[i][z])*rho2p + (blist[i][z]*elist[j][z] + blist[j][z]*elist[i][z])*rho4p + (elist[i][z]*alist[j][z] +elist[j][z]*alist[i][z])*rho5p for i,j in bin_pairs]\n",
    "        dxim = [alist[i][z]*alist[j][z]*rho0m + blist[i][z]*blist[j][z]*rho1m + elist[i][z]*elist[j][z]*rho3m + (blist[i][z]*alist[j][z] + blist[j][z]*alist[i][z])*rho2m + (blist[i][z]*elist[j][z] + blist[j][z]*elist[i][z])*rho4m + (elist[i][z]*alist[j][z] +elist[j][z]*alist[i][z])*rho5m for i,j in bin_pairs]\n",
    "        dxi = dxip + dxim\n",
    "        veclist.append(np.concatenate(np.c_[dxi]))\n",
    "    covmat = np.cov(np.c_[veclist].T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe29e0-8333-4aec-8614-5de49a7e457b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "al = []\n",
    "bl = []\n",
    "el = []\n",
    "with h5py.File(path+'tau_stats.hdf5') as f:\n",
    "    for n in range(nbins):\n",
    "        al.append(np.asarray(f[f'tau_statistics/bestfits_PSF-reserved/bin_{n}/alpha']))\n",
    "        bl.append(np.asarray(f[f'tau_statistics/bestfits_PSF-reserved/bin_{n}/beta']))\n",
    "        el.append(np.asarray(f[f'tau_statistics/bestfits_PSF-reserved/bin_{n}/eta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9ca04-6311-4b82-a3c7-3268b45717a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Writting final contamination\n",
    "hdu = fits.PrimaryHDU()\n",
    "hdul = fits.HDUList([hdu])\n",
    "\n",
    "dxip_list = []; dxim_list = []; bin1_list = []; bin2_list = []; angbin_list = []; ang_list = []\n",
    "covxip_list = []; covxim_list = []\n",
    "\n",
    "\n",
    "for i,j in bin_pairs:\n",
    "    dxip = al[i]*al[j]*rho0p + bl[i]*bl[j]*rho1p + (bl[i]*al[j] + bl[j]*al[i])*rho2p + el[i]*el[j]*rho3p + (el[i]*al[j] +el[j]*al[i])*rho4p + (bl[i]*el[j] + bl[j]*el[i])*rho5p \n",
    "    dxim = al[i]*al[j]*rho0m + bl[i]*bl[j]*rho1m + (bl[i]*al[j] + bl[j]*al[i])*rho2m + el[i]*el[j]*rho3m + (el[i]*al[j] +el[j]*al[i])*rho4m + (bl[i]*el[j] + bl[j]*el[i])*rho5m\n",
    "\n",
    "\n",
    "    ang_list.append(meanr)\n",
    "    bin1_list.append(np.array( [i + 1]*len(meanr)))\n",
    "    bin2_list.append(np.array( [j + 1]*len(meanr)))\n",
    "    angbin_list.append(np.arange(len(meanr)))\n",
    "    dxip_list.append(dxip)\n",
    "    dxim_list.append(dxim)\n",
    "\n",
    "hdul.insert(1, fits.ImageHDU(covmat, name='COVMAT'))\n",
    "bin1array = np.concatenate(bin1_list)\n",
    "bin2array = np.concatenate(bin2_list)\n",
    "angbinarray = np.concatenate(angbin_list)\n",
    "valuearray = np.concatenate(dxip_list)\n",
    "angarray = np.concatenate(ang_list)\n",
    "\n",
    "##Format of the fit file output\n",
    "names=['BIN1', 'BIN2','ANGBIN', 'VALUE', 'ANG']\n",
    "forms = ['i4', 'i4', 'i4',  'f4',  'f4']\n",
    "dtype = dict(names = names, formats=forms)\n",
    "nrows = len(angarray)\n",
    "outdata = np.recarray((nrows, ), dtype=dtype)\n",
    "array_list = [bin1array, bin2array, angbinarray, valuearray, angarray ]\n",
    "for array, name in zip(array_list, names): outdata[name] = array \n",
    "corrhdu = fits.BinTableHDU(outdata, name='delta_xip')\n",
    "hdul.insert(2, corrhdu)\n",
    "valuearray = np.concatenate(dxim_list)\n",
    "array_list = [bin1array, bin2array, angbinarray, valuearray, angarray ]\n",
    "for array, name in zip(array_list, names): outdata[name] = array \n",
    "corrhdu = fits.BinTableHDU(outdata, name='delta_xim')\n",
    "hdul.insert(3, corrhdu)\n",
    "hdul.writeto('DES_contaminant.fits', overwrite=True)\n",
    "print('Written!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975faff-a0da-4226-87ea-29741e6cf2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contaminate DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57603e-c21a-431b-97a8-305b8e081d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the theory data vector files will all be in the cosmosis output folders:\n",
    "# des: '../cosmosis-standard-library/chain_output/DES-Y3/TheoryDV.txt'\n",
    "# hsc: '../hscy3/TXdata/'\n",
    "# kids: '../KiDS/TXdata/'\n",
    "\n",
    "#copy and paste the path you want here:\n",
    "des_dv= '../cosmosis_files/datavec/theory/simulated_theoryDV.fits'\n",
    "\n",
    "#DES and HSC have 4 bins, KiDS has 5.\n",
    "nbins=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a66c46-9223-441a-a351-d462bc0fe090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(covmatrix, lengths, name):\n",
    "    import numpy as np\n",
    "    if name is not None:\n",
    "        if (name=='xip'):\n",
    "            start = 0\n",
    "            end =start + lengths[0]\n",
    "        elif (name=='xim'):\n",
    "            start = lengths[0]\n",
    "            end =start + lengths[1]\n",
    "        elif (name=='gammat'):\n",
    "            start = lengths[0] + lengths[1]\n",
    "            end =start + lengths[2]\n",
    "        elif (name=='wtheta'):\n",
    "            start = lengths[0] + lengths[1]+ lengths[2]\n",
    "            end =start + lengths[3]\n",
    "        return np.diagonal(covmatrix)[start:end]**0.5\n",
    "    else:\n",
    "        print(\"Correlation function not defined\")\n",
    "        return None\n",
    "\n",
    "import fitsio\n",
    "covmatrixfit_ori=fitsio.read(des_dv,ext=1)\n",
    "xipfit_ori=fitsio.read(des_dv,ext=2)\n",
    "ximfit_ori=fitsio.read(des_dv,ext=3)\n",
    "\n",
    "#read contaminant\n",
    "covmatrixfit_cont=fitsio.read('DES_contaminant.fits',ext=1)\n",
    "xipfit_cont=fitsio.read('DES_contaminant.fits',ext=2)\n",
    "ximfit_cont=fitsio.read('DES_contaminant.fits',ext=3)\n",
    "dxipbin = xipfit_cont['VALUE']\n",
    "dximbin = ximfit_cont['VALUE']\n",
    "\n",
    "nsig = 2\n",
    "lengths = [len(xipfit_cont), len(ximfit_cont)]\n",
    "\n",
    "'''\n",
    "if args.sup:\n",
    "    dxipbin += nsig*get_error(covmatrixfit_cont, lengths, 'xip')\n",
    "    dximbin += nsig*get_error(covmatrixfit_cont, lengths, 'xim')\n",
    "if args.inf:\n",
    "    dxipbin -= nsig*get_error(covmatrixfit_cont, lengths, 'xip')\n",
    "    dximbin -= nsig*get_error(covmatrixfit_cont, lengths, 'xim')\n",
    "'''\n",
    "\n",
    "nrows = 20\n",
    "a=[i for i in range(1,nbins+1)]\n",
    "b=[j for j in range(1,nbins+1)]\n",
    "bin_pairs=[]\n",
    "for p in itertools.product(a, b):\n",
    "    bin_pairs.append(p)\n",
    "for i,j in bin_pairs:\n",
    "    binp = (xipfit_ori['BIN1']==i)&(xipfit_ori['BIN2']==j)\n",
    "    binm = (ximfit_ori['BIN1']==i)&(ximfit_ori['BIN2']==j)\n",
    "    idxbinsp =  list(itertools.compress(range(len(binp)),  binp))\n",
    "    idxbinsm =  list(itertools.compress(range(len(binm)),  binm))\n",
    "    if (len(idxbinsp)!=0): xipfit_ori['VALUE'][binp] -=dxipbin[binp]\n",
    "    if (len(idxbinsm)!=0): ximfit_ori['VALUE'][binm] -=dximbin[binm]\n",
    "\n",
    "hdulist = fits.open(des_dv)\n",
    "#delete all xip, xim but keep header\n",
    "oldheaders =  [hdulist[2].header, hdulist[3].header]\n",
    "hdulist.pop(index=2);\n",
    "hdulist.pop(index=2);\n",
    "\n",
    "xiphdu = fits.BinTableHDU(xipfit_ori)\n",
    "ximhdu = fits.BinTableHDU(ximfit_ori)\n",
    "hdulist.insert(2, xiphdu)\n",
    "hdulist.insert(3, ximhdu)\n",
    "hdulist[2].header = oldheaders[0]\n",
    "hdulist[3].header = oldheaders[1]\n",
    "hdulist.writeto('../cosmosis_files/datavec/contaminated/DES-Y3_contaminated_2sig.fits', overwrite=True)\n",
    "print('written')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntenv",
   "language": "python",
   "name": "ntenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
