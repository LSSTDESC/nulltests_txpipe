{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9208e67e-b5d7-4e18-bff8-a2752687bd8a",
   "metadata": {},
   "source": [
    "making psf bias DV and contaminate simulated theory datavector <br>\n",
    "based on code from here:  https://github.com/des-science/Y3_shearcat_tests/blob/212c03bfc239c9cff5419efbe70bdfdba28639ec/alpha-beta-eta-test/code/produce_2pcfpsfbias.py\n",
    " <br> and here: https://github.com/des-science/Y3_shearcat_tests/blob/master/alpha-beta-eta-test/forecast/contaminate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0907aae-bd26-4bab-9c0a-f3693b7c9a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "from astropy.io import fits\n",
    "import itertools\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1195c7f-478c-40b9-8bbe-28b42bde41dd",
   "metadata": {},
   "source": [
    "# Make Contaminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99d4c93-5306-4d3d-a8bd-a88607240ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the relevant files will all be in the TXdata folders:\n",
    "# des: '../desy3/TXdata/'\n",
    "# hsc: '../hscy3/TXdata/'\n",
    "# kids: '../KiDS/TXdata/'\n",
    "\n",
    "#copy and paste the path you want here:\n",
    "path= '../KiDS/TXdata/NEWruns/'\n",
    "\n",
    "#DES and HSC have 4 bins, KiDS has 5.\n",
    "nbins=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646077a9-9927-4ac9-bee6-a8ea04289ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load rowes\n",
    "with h5py.File(path+'rowe_stats-250JK-catms-9bin.hdf5') as f:\n",
    "    meanr = f['rowe_statistics/rowe_0_PSF-reserved/theta'][:]\n",
    "    rho0p = f['rowe_statistics/rowe_0_PSF-reserved/xi_plus'][:]\n",
    "    rho0m = f['rowe_statistics/rowe_0_PSF-reserved/xi_minus'][:]\n",
    "    rho1p = f['rowe_statistics/rowe_1_PSF-reserved/xi_plus'][:]\n",
    "    rho1m = f['rowe_statistics/rowe_1_PSF-reserved/xi_minus'][:]\n",
    "    rho2p = f['rowe_statistics/rowe_2_PSF-reserved/xi_plus'][:]\n",
    "    rho2m = f['rowe_statistics/rowe_2_PSF-reserved/xi_minus'][:]\n",
    "    rho3p = f['rowe_statistics/rowe_3_PSF-reserved/xi_plus'][:]\n",
    "    rho3m = f['rowe_statistics/rowe_3_PSF-reserved/xi_minus'][:]\n",
    "    rho4p = f['rowe_statistics/rowe_4_PSF-reserved/xi_plus'][:]\n",
    "    rho4m = f['rowe_statistics/rowe_4_PSF-reserved/xi_minus'][:]\n",
    "    rho5p = f['rowe_statistics/rowe_5_PSF-reserved/xi_plus'][:]\n",
    "    rho5m = f['rowe_statistics/rowe_5_PSF-reserved/xi_minus'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8358394-200a-4ce0-a804-1dc2d733d8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load tau fitting chains\n",
    "alist = []\n",
    "blist = []\n",
    "elist = []\n",
    "with h5py.File(path+'tau_stats-250JK-catms-9bin.hdf5') as f:\n",
    "    for n in range(nbins):\n",
    "        alist.append(f[f'tau_statistics/chain_bestfits_PSF-reserved/bin_{n}/alpha'][:])\n",
    "        blist.append(f[f'tau_statistics/chain_bestfits_PSF-reserved/bin_{n}/beta'][:])\n",
    "        elist.append(f[f'tau_statistics/chain_bestfits_PSF-reserved/bin_{n}/eta'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e12af61-57f8-4283-ae3c-574ab1118f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for HSC, we're going to make rho0m all zeros since they're different lengths\n",
    "# and cosmosis does not handle that correctly at the moment, so we're considering a xip-only inference \n",
    "#rho0m = rho1m = rho2m = rho3m = rho4m = rho5m = np.zeros(13)\n",
    "\n",
    "a=[i for i in range(nbins)]\n",
    "bin_pairs=[]\n",
    "for p in itertools.combinations_with_replacement(a, 2): bin_pairs.append(p)\n",
    "veclist = []\n",
    "for z in range(len(alist[0])):\n",
    "    dxip = [alist[i][z]*alist[j][z]*rho0p + blist[i][z]*blist[j][z]*rho1p + elist[i][z]*elist[j][z]*rho3p + (blist[i][z]*alist[j][z] + blist[j][z]*alist[i][z])*rho2p + (blist[i][z]*elist[j][z] + blist[j][z]*elist[i][z])*rho4p + (elist[i][z]*alist[j][z] +elist[j][z]*alist[i][z])*rho5p for i,j in bin_pairs]\n",
    "    dxim = [alist[i][z]*alist[j][z]*rho0m + blist[i][z]*blist[j][z]*rho1m + elist[i][z]*elist[j][z]*rho3m + (blist[i][z]*alist[j][z] + blist[j][z]*alist[i][z])*rho2m + (blist[i][z]*elist[j][z] + blist[j][z]*elist[i][z])*rho4m + (elist[i][z]*alist[j][z] +elist[j][z]*alist[i][z])*rho5m for i,j in bin_pairs]\n",
    "    dxi = dxip + dxim\n",
    "    veclist.append(np.concatenate(np.c_[dxi]))\n",
    "covmat = np.cov(np.c_[veclist].T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbe29e0-8333-4aec-8614-5de49a7e457b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "al = []\n",
    "bl = []\n",
    "el = []\n",
    "with h5py.File(path+'tau_stats-250JK-catms-9bin.hdf5') as f:\n",
    "    for n in range(nbins):\n",
    "        al.append(np.asarray(f[f'tau_statistics/bestfits_PSF-reserved/bin_{n}/alpha']))\n",
    "        bl.append(np.asarray(f[f'tau_statistics/bestfits_PSF-reserved/bin_{n}/beta']))\n",
    "        el.append(np.asarray(f[f'tau_statistics/bestfits_PSF-reserved/bin_{n}/eta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65c754-343b-4f83-8577-db0a235ef640",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#load rowes\n",
    "with h5py.File(path+'rowe_stats-interp.hdf5') as f:\n",
    "    meanr = f['rowe_statistics/rowe_0_PSF-reserved/theta'][:]\n",
    "    rho0p = f['rowe_statistics/rowe_0_PSF-reserved/xi_plus'][:]\n",
    "    rho0m = f['rowe_statistics/rowe_0_PSF-reserved/xi_minus'][:]\n",
    "    rho1p = f['rowe_statistics/rowe_1_PSF-reserved/xi_plus'][:]\n",
    "    rho1m = f['rowe_statistics/rowe_1_PSF-reserved/xi_minus'][:]\n",
    "    rho2p = f['rowe_statistics/rowe_2_PSF-reserved/xi_plus'][:]\n",
    "    rho2m = f['rowe_statistics/rowe_2_PSF-reserved/xi_minus'][:]\n",
    "    rho3p = f['rowe_statistics/rowe_3_PSF-reserved/xi_plus'][:]\n",
    "    rho3m = f['rowe_statistics/rowe_3_PSF-reserved/xi_minus'][:]\n",
    "    rho4p = f['rowe_statistics/rowe_4_PSF-reserved/xi_plus'][:]\n",
    "    rho4m = f['rowe_statistics/rowe_4_PSF-reserved/xi_minus'][:]\n",
    "    rho5p = f['rowe_statistics/rowe_5_PSF-reserved/xi_plus'][:]\n",
    "    rho5m = f['rowe_statistics/rowe_5_PSF-reserved/xi_minus'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75e9ca04-6311-4b82-a3c7-3268b45717a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written!\n"
     ]
    }
   ],
   "source": [
    "#Writting final contamination\n",
    "hdu = fits.PrimaryHDU()\n",
    "hdul = fits.HDUList([hdu])\n",
    "\n",
    "dxip_list = []; dxim_list = []; bin1_listp = []; bin2_listp = []; angbin_listp = []; ang_listp = [];\n",
    "bin1_listm = []; bin2_listm = []; angbin_listm = []; ang_listm = []\n",
    "covxip_list = []; covxim_list = []\n",
    "\n",
    "\n",
    "for i,j in bin_pairs:\n",
    "    dxip = al[i]*al[j]*rho0p + bl[i]*bl[j]*rho1p + (bl[i]*al[j] + bl[j]*al[i])*rho2p + el[i]*el[j]*rho3p + (bl[i]*el[j] + bl[j]*el[i])*rho4p + (el[i]*al[j] +el[j]*al[i])*rho5p\n",
    "    dxim = al[i]*al[j]*rho0m + bl[i]*bl[j]*rho1m + (bl[i]*al[j] + bl[j]*al[i])*rho2m + el[i]*el[j]*rho3m + (bl[i]*el[j] + bl[j]*el[i])*rho4m + (el[i]*al[j] +el[j]*al[i])*rho5m\n",
    "\n",
    "    ##COMMMENT FOR HSC:\n",
    "    meanrp=meanrm=meanr\n",
    "    \n",
    "    \n",
    "    ang_listp.append(meanrp)\n",
    "    bin1_listp.append(np.array( [i + 1]*len(meanrp)))\n",
    "    bin2_listp.append(np.array( [j + 1]*len(meanrp)))\n",
    "    angbin_listp.append(np.arange(len(meanrp)))\n",
    "    \n",
    "    ang_listm.append(meanrm)\n",
    "    bin1_listm.append(np.array( [i + 1]*len(meanrm)))\n",
    "    bin2_listm.append(np.array( [j + 1]*len(meanrm)))\n",
    "    angbin_listm.append(np.arange(len(meanrm)))\n",
    "    \n",
    "    dxip_list.append(dxip)\n",
    "    dxim_list.append(dxim)\n",
    "\n",
    "hdul.insert(1, fits.ImageHDU(covmat, name='COVMAT'))\n",
    "bin1arrayp = np.concatenate(bin1_listp)\n",
    "bin2arrayp = np.concatenate(bin2_listp)\n",
    "angbinarrayp = np.concatenate(angbin_listp)\n",
    "valuearray = np.concatenate(dxip_list)\n",
    "angarrayp = np.concatenate(ang_listp)\n",
    "\n",
    "bin1arraym = np.concatenate(bin1_listm)\n",
    "bin2arraym = np.concatenate(bin2_listm)\n",
    "angbinarraym = np.concatenate(angbin_listm)\n",
    "angarraym = np.concatenate(ang_listm)\n",
    "\n",
    "##Format of the fit file output\n",
    "names=['BIN1', 'BIN2','ANGBIN', 'VALUE', 'ANG']\n",
    "forms = ['i4', 'i4', 'i4',  'f4',  'f4']\n",
    "dtype = dict(names = names, formats=forms)\n",
    "nrows = len(angarrayp)\n",
    "outdata = np.recarray((nrows, ), dtype=dtype)\n",
    "array_list = [bin1arrayp, bin2arrayp, angbinarrayp, valuearray, angarrayp ]\n",
    "for array, name in zip(array_list, names): outdata[name] = array \n",
    "corrhdu = fits.BinTableHDU(outdata, name='delta_xip')\n",
    "hdul.insert(2, corrhdu)\n",
    "nrows = len(angarraym)\n",
    "outdata = np.recarray((nrows, ), dtype=dtype)\n",
    "valuearray = np.concatenate(dxim_list)\n",
    "array_list = [bin1arraym, bin2arraym, angbinarraym, valuearray, angarraym ]\n",
    "for array, name in zip(array_list, names): outdata[name] = array \n",
    "corrhdu = fits.BinTableHDU(outdata, name='delta_xim')\n",
    "hdul.insert(3, corrhdu)\n",
    "hdul.writeto('NEWruns/KiDS-1000/KiDS-1000_contaminant_250JK-catms.fits', overwrite=True)\n",
    "print('Written!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975faff-a0da-4226-87ea-29741e6cf2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contaminate DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d57603e-c21a-431b-97a8-305b8e081d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the theory data vector files will all be in the cosmosis output folders:\n",
    "# des: '../cosmosis-files/datavec/theory/DESsimulated_theoryDV.fits'\n",
    "# hsc: '../cosmosis_files/datavec/theory/HSCsimulated_theoryDV.fits'\n",
    "# kids: '../cosmosis_files/datavec/theory/KiDSsimulated_theoryDV.fits'\n",
    "\n",
    "#copy and paste the path you want here:\n",
    "dv= '../cosmosis_files/datavec/theory/KiDSsimulated_theoryDV.fits'\n",
    "\n",
    "#DES and HSC have 4 bins, KiDS has 5.\n",
    "nbins=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2838e7e-1d6d-4994-b4b2-6358fa67fe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06a66c46-9223-441a-a351-d462bc0fe090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written\n"
     ]
    }
   ],
   "source": [
    "def get_error(covmatrix, lengths, name):\n",
    "    import numpy as np\n",
    "    if name is not None:\n",
    "        if (name=='xip'):\n",
    "            start = 0\n",
    "            end =start + lengths[0]\n",
    "        elif (name=='xim'):\n",
    "            start = lengths[0]\n",
    "            end =start + lengths[1]\n",
    "        elif (name=='gammat'):\n",
    "            start = lengths[0] + lengths[1]\n",
    "            end =start + lengths[2]\n",
    "        elif (name=='wtheta'):\n",
    "            start = lengths[0] + lengths[1]+ lengths[2]\n",
    "            end =start + lengths[3]\n",
    "        return np.diagonal(covmatrix)[start:end]**0.5\n",
    "    else:\n",
    "        print(\"Correlation function not defined\")\n",
    "        return None\n",
    "\n",
    "import fitsio\n",
    "covmatrixfit_ori=fitsio.read(dv,ext=1)\n",
    "xipfit_ori=fitsio.read(dv,ext=2)\n",
    "ximfit_ori=fitsio.read(dv,ext=3)\n",
    "\n",
    "#read contaminant\n",
    "covmatrixfit_cont=fitsio.read('NEWruns/KiDS-1000/KiDS-1000_contaminant_250JK-catms.fits',ext=1)\n",
    "xipfit_cont=fitsio.read('NEWruns/KiDS-1000/KiDS-1000_contaminant_250JK-catms.fits',ext=2)\n",
    "ximfit_cont=fitsio.read('NEWruns/KiDS-1000/KiDS-1000_contaminant_250JK-catms.fits',ext=3)\n",
    "dxipbin = xipfit_cont['VALUE']\n",
    "dximbin = ximfit_cont['VALUE']\n",
    "\n",
    "nsig = 2\n",
    "lengths = [len(xipfit_cont), len(ximfit_cont)]\n",
    "# run both, uncomment which one you need \n",
    "#upper bound:\n",
    "dxipbin += nsig*get_error(covmatrixfit_cont, lengths, 'xip')\n",
    "dximbin += nsig*get_error(covmatrixfit_cont, lengths, 'xim')\n",
    "#lower bound:\n",
    "#dxipbin -= nsig*get_error(covmatrixfit_cont, lengths, 'xip')\n",
    "#dximbin -= nsig*get_error(covmatrixfit_cont, lengths, 'xim')\n",
    "\n",
    "\n",
    "a=[i for i in range(1,nbins+1)]\n",
    "b=[j for j in range(1,nbins+1)]\n",
    "bin_pairs=[]\n",
    "for p in itertools.product(a, b):\n",
    "    bin_pairs.append(p)\n",
    "for i,j in bin_pairs:\n",
    "    binp = (xipfit_ori['BIN1']==i)&(xipfit_ori['BIN2']==j)\n",
    "    binm = (ximfit_ori['BIN1']==i)&(ximfit_ori['BIN2']==j)\n",
    "    idxbinsp =  list(itertools.compress(range(len(binp)),  binp))\n",
    "    idxbinsm =  list(itertools.compress(range(len(binm)),  binm))\n",
    "    if (len(idxbinsp)!=0): xipfit_ori['VALUE'][binp] -=dxipbin[binp]\n",
    "    if (len(idxbinsm)!=0): ximfit_ori['VALUE'][binm] -=dximbin[binm]\n",
    "\n",
    "hdulist = fits.open(dv)\n",
    "#delete all xip, xim but keep header\n",
    "oldheaders =  [hdulist[2].header, hdulist[3].header]\n",
    "hdulist.pop(index=2);\n",
    "hdulist.pop(index=2);\n",
    "\n",
    "xiphdu = fits.BinTableHDU(xipfit_ori)\n",
    "ximhdu = fits.BinTableHDU(ximfit_ori)\n",
    "hdulist.insert(2, xiphdu)\n",
    "hdulist.insert(3, ximhdu)\n",
    "hdulist[2].header = oldheaders[0]\n",
    "hdulist[3].header = oldheaders[1]\n",
    "hdulist.writeto('../cosmosis_files/datavec/contaminated/NEWruns/KiDS_1000/KiDS-1000_Contaminated_2sig_250JK_catms_sup.fits', overwrite=True)\n",
    "print('written')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f439e-545e-4617-9135-a86ebb0a7ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntenv",
   "language": "python",
   "name": "ntenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
